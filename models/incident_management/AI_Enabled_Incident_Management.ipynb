{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CVfR3NmdsAg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEjlsDsdd0FX"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8Fzkwjyd6JA",
    "outputId": "50b698aa-1478-4fce-c74c-f44a6e24faed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! Yes, I’m here and ready to help. What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello GPT-5, are you working?\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APeTBZP2d9YX"
   },
   "outputs": [],
   "source": [
    "log_data = \"\"\"\n",
    "2025-09-18 02:10:21 INFO Starting server on port 8080\n",
    "2025-09-18 02:10:25 WARNING High memory usage detected: 85%\n",
    "2025-09-18 02:10:27 ERROR Database connection failed\n",
    "2025-09-18 02:10:31 INFO Retrying database connection\n",
    "2025-09-18 02:10:35 ERROR Database connection failed\n",
    "2025-09-18 02:10:40 CRITICAL Service unavailable due to repeated DB failures\n",
    "\"\"\"\n",
    "\n",
    "with open(\"system_logs.txt\", \"w\") as f:\n",
    "    f.write(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anagtzfTj16I",
    "outputId": "4e3ff2e8-b1d4-432d-adf9-feb4315975c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw logs:\n",
      " \n",
      "2025-09-18 02:10:21 INFO Starting server on port 8080\n",
      "2025-09-18 02:10:25 WARNING High memory usage detected: 85%\n",
      "2025-09-18 02:10:27 ERROR Database connection failed\n",
      "2025-09-18 02:10:31 INFO Retrying database connection\n",
      "2025-09-18 02:10:35 ERROR Database connection failed\n",
      "2025-09-18 02:10:40 CRITICAL Service unavailable due to repeated DB failures\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"system_logs.txt\", \"r\") as f:\n",
    "    logs = f.read()\n",
    "\n",
    "print(\"Raw logs:\\n\", logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af2z2shuj849",
    "outputId": "3a284043-51c0-458c-9e1b-126d78c8dd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The server started up on port 8080.\n",
      "- Right after starting, it reported high memory usage (85%).\n",
      "- The application tried to connect to its database but failed.\n",
      "- It attempted a retry, but the database connection failed again.\n",
      "- After repeated failures, the service declared itself unavailable because it can’t operate without a working database connection.\n",
      "\n",
      "In short: the service came up, was under memory pressure, couldn’t reach its database despite retrying, and shut itself off to avoid running in a broken state.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert IT assistant who helps analyze server logs.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here are some system logs:\\n{logs}\\n\\nPlease explain in simple terms what is happening.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRMKRO0C4VVd",
    "outputId": "4b2d805a-74c3-4c5e-d237-18db2d361a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity: P1 (Critical)\n",
      "\n",
      "Rationale:\n",
      "- The logs show repeated database connection failures without recovery.\n",
      "- The final entry explicitly states \"CRITICAL Service unavailable due to repeated DB failures,\" indicating the service is unavailable.\n",
      "- Service unavailability implies customer-impacting outage, meeting P1 criteria.\n",
      "- The earlier high memory warning may be a contributing factor but the decisive signal is the outage due to DB failures.\n"
     ]
    }
   ],
   "source": [
    "classification_prompt = f\"\"\"\n",
    "You are an expert Site Reliability Engineer.\n",
    "Read the following logs and classify the incident severity as:\n",
    "- P1 (Critical): service down or customer impact\n",
    "- P2 (High): service degraded, limited impact\n",
    "- P3 (Low): minor issue, warning only\n",
    "\n",
    "Explain rationale behind final classification.\n",
    "\n",
    "Logs:\n",
    "{logs}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\", messages=[{\"role\": \"user\", \"content\": classification_prompt}]\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48bTUrZr4V6A",
    "outputId": "1acb394c-e2f4-47be-cfa7-c851c64d6d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Summary:\n",
      "- The service started on port 8080, then immediately reported high memory usage (85%).\n",
      "- Attempts to connect to the database failed twice in quick succession, leading to the service becoming unavailable due to repeated DB failures.\n",
      "\n",
      "2) Possible root cause hints:\n",
      "- Database endpoint down or unreachable (DB outage, maintenance, crash).\n",
      "- Misconfigured DB connection settings or secrets (host/port, DNS name, credentials, SSL/TLS parameters).\n",
      "- Network/DNS issues between app and DB (firewall/security group rules, routing, DNS resolution failure).\n",
      "- DB connection exhaustion or limits reached (max_connections, pool misconfiguration, connection leak).\n",
      "- High memory pressure on the app host causing resource starvation or OOM-affected operations.\n",
      "- Recent deployment or config change impacting connectivity or authentication.\n",
      "- TLS/certificate issues (expired certs, CA trust not configured, server now requiring SSL).\n",
      "- Timeouts too aggressive for current latency, causing connection attempts to fail.\n"
     ]
    }
   ],
   "source": [
    "summary_prompt = f\"\"\"\n",
    "You are an expert Incident Response Assistant.\n",
    "Read the following logs and provide:\n",
    "1. A short summary (2-3 sentences) in plain English.\n",
    "2. Possible root cause hints (bullet points).\n",
    "\n",
    "Logs:\n",
    "{logs}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\", messages=[{\"role\": \"user\", \"content\": summary_prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMQFGwHutNQ4"
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import os\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "\n",
    "def send_email_alert(message: str):\n",
    "    sender_email = os.getenv(\"SENDER_EMAIL\")\n",
    "    receiver_email = os.getenv(\"RECEIVER_EMAIL\")\n",
    "    app_password = os.getenv(\"EMAIL_APP_PASSWORD\")  # Use Google App Password\n",
    "\n",
    "    subject = \"Incident Alert from GPT-5\"\n",
    "\n",
    "    # Build the email\n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg.attach(MIMEText(message, \"plain\"))\n",
    "\n",
    "    # Send the email\n",
    "    try:\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "        server.starttls()\n",
    "        server.login(sender_email, app_password)\n",
    "        server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "        server.quit()\n",
    "        print(\"[EMAIL SENT] \" + message)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] Failed to send email:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pg6xNLTru4gn"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"send_email_alert\",\n",
    "            \"description\": \"Send an email alert to the incident response team\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"message\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"message\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8qUGKAVvKue",
    "outputId": "accf0c80-e0d6-40d8-e4a7-f081290e92f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CKr7HpNS3iBumO67Zast0R60xtvGU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here’s a concise incident analysis based on the provided logs.\\n\\nSummary\\n- The application experienced repeated database connection failures culminating in a critical service outage.\\n- Timeframe: 2025-09-18 02:10:27 to 02:10:40 (13 seconds from first error to outage).\\n- Impact: Service unavailable due to inability to reach the database; likely full outage for the affected service.\\n\\nTimeline\\n- 02:10:27 ERROR: Database connection failed\\n- 02:10:35 ERROR: Database connection failed\\n- 02:10:40 CRITICAL: Service unavailable due to repeated DB failures\\n\\nSeverity\\n- SEV-1 (customer-impacting outage)\\n\\nMost likely causes (ranked)\\n1) Database unreachable (DB host down, failover in progress, maintenance, crash/restart)\\n2) Network issues between app and DB (security group/firewall change, routing/DNS problem, TLS/cert issues)\\n3) Resource exhaustion or limits (max_connections reached, connection pool exhaustion, CPU/memory saturation on DB)\\n4) Configuration/credential issues (rotated/expired creds, changed connection string)\\n5) Recent deploy/config change impacting DB connectivity\\n\\nImmediate actions (runbook-style)\\n- Verify DB reachability:\\n  - From app host/pod: nc -vz <db_host> <db_port> or telnet; check DNS resolution.\\n  - Attempt direct query: psql/mysql cli select 1 (or vendor equivalent).\\n- Check DB health/availability:\\n  - Review DB logs/console (e.g., RDS/Aurora status, failover events, maintenance windows).\\n  - Confirm no ongoing backup/maintenance/failover.\\n- Inspect connection saturation:\\n  - Check max_connections and current connections; kill stale sessions if safe.\\n  - Review app connection pool metrics; restart app pods if pool is wedged.\\n- Review recent changes:\\n  - Any deploys/config/secret rotations between 02:10:20–02:10:40? Roll back if suspected.\\n- Network/security:\\n  - Validate security groups/firewall rules to DB port; recent ruleset changes; TLS cert validity.\\n- Stabilize service:\\n  - Enable circuit breakers/backoff to DB; reduce retry storm.\\n  - Fail over to replica/standby if available; or restart DB if it’s crashed and no failover exists.\\n\\nData needed to proceed\\n- DB type/version and hosting (e.g., Postgres on RDS, MySQL, etc.)\\n- App environment/cluster (k8s/VMs) and region\\n- Any recent deploys or secret rotations near 02:10 UTC\\n- Current DB metrics (connections, CPU, storage, replication/cluster state)\\n- Network changes (firewall/SG, routing, DNS) in last hour\\n\\nNext steps (after stabilization)\\n- Add/connectivity SLO-based alerts on connection errors and DB availability.\\n- Implement jittered retries and circuit breaking to avoid thundering herds.\\n- Validate connection pool sizing and max_connections alignment.\\n- Ensure automated failover tested and documented.\\n\\nDo you want me to alert the incident response team now? I can send an email summary and page on-call immediately.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759086775, model='gpt-5-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1559, prompt_tokens=200, total_tokens=1759, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=896, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "incident_logs = \"\"\"\n",
    "2025-09-18 02:10:27 ERROR Database connection failed\n",
    "2025-09-18 02:10:35 ERROR Database connection failed\n",
    "2025-09-18 02:10:40 CRITICAL Service unavailable due to repeated DB failures\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI that monitors incidents.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze these logs:\\n{incident_logs}\"},\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcM3gZLsxh0o",
    "outputId": "6e13fb00-a6a8-487b-cac8-8dd4a4be01b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-5 Output: Severity: P1\n",
      "Summary: Service outage caused by repeated database connection failures.\n",
      "[EMAIL SENT] [P1 CRITICAL] Database unavailable due to repeated failures | Escalating to manager.\n",
      "[ACTION] Emailed ops + manager. War room escalation triggered.\n"
     ]
    }
   ],
   "source": [
    "def escalation_workflow(severity: str, summary: str):\n",
    "    if severity == \"P3\":\n",
    "        return \"[NO ACTION] Logged only.\"\n",
    "    elif severity == \"P2\":\n",
    "        # Email ops team\n",
    "        send_email_alert(f\"[P2 Incident] {summary}\")\n",
    "        return \"[ACTION] Emailed ops team.\"\n",
    "    elif severity == \"P1\":\n",
    "        # Email ops team + escalate to manager\n",
    "        send_email_alert(f\"[P1 CRITICAL] {summary} | Escalating to manager.\")\n",
    "        # (Optional: call calendar tool to schedule war room)\n",
    "        return \"[ACTION] Emailed ops + manager. War room escalation triggered.\"\n",
    "    else:\n",
    "        return \"[UNKNOWN] No matching workflow.\"\n",
    "\n",
    "\n",
    "incident_logs = \"\"\"\n",
    "2025-09-18 02:10:27 ERROR Database connection failed\n",
    "2025-09-18 02:10:35 ERROR Database connection failed\n",
    "2025-09-18 02:10:40 CRITICAL Service unavailable due to repeated DB failures\n",
    "\"\"\"\n",
    "\n",
    "classification_prompt = f\"\"\"\n",
    "You are an expert incident classifier.\n",
    "Classify the severity as P1, P2, or P3 and give a 1-line summary.\n",
    "\n",
    "Logs:\n",
    "{incident_logs}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\", messages=[{\"role\": \"user\", \"content\": classification_prompt}]\n",
    ")\n",
    "\n",
    "ai_output = response.choices[0].message.content\n",
    "print(\"GPT-5 Output:\", ai_output)\n",
    "\n",
    "# Example: Parse severity + summary (simplified for demo)\n",
    "severity = \"P1\"\n",
    "summary = \"Database unavailable due to repeated failures\"\n",
    "\n",
    "# Run workflow\n",
    "result = escalation_workflow(severity, summary)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mV8cWgnizvKw",
    "outputId": "f76c01ea-1bdc-40f4-c31d-9bc6ec1319e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file size: 101 lines\n"
     ]
    }
   ],
   "source": [
    "# Create a fake \"large\" log with repeating patterns\n",
    "large_logs = (\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            f\"2025-09-18 02:{i:02d}:00 ERROR Database connection failed\"\n",
    "            for i in range(100)\n",
    "        ]\n",
    "    )\n",
    "    + \"\\n2025-09-18 03:00:00 CRITICAL Service unavailable\"\n",
    ")\n",
    "\n",
    "with open(\"large_logs.txt\", \"w\") as f:\n",
    "    f.write(large_logs)\n",
    "\n",
    "print(\"Log file size:\", len(large_logs.splitlines()), \"lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HklpVOXA0Nwh",
    "outputId": "1b18a890-6886-44f4-f0cd-b95a681d464e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Summary:\n",
      "- Starting at 02:00, the application repeatedly failed to connect to the database for about an hour.\n",
      "- At 03:00, the issue escalated to a full service outage (CRITICAL: Service unavailable), indicating customer-facing impact.\n",
      "- The logs include malformed timestamps (02:60–02:99), suggesting a logging/clock or ingestion anomaly in addition to the database issue.\n",
      "\n",
      "2) Final incident severity: P1\n",
      "\n",
      "3) Root cause hints:\n",
      "- Database unavailable: host/cluster outage, maintenance, failover stuck, or storage/CPU exhaustion on the DB.\n",
      "- Network/access: firewall/security group change, route/DNS issue, VPC peering or load balancer change blocking DB access.\n",
      "- Authentication/TLS: expired/rotated DB credentials or certificates not deployed to the app.\n",
      "- Connection exhaustion: app-side connection leak or pool misconfiguration hitting max_connections from ~02:00 onward.\n",
      "- Recent change: config/deployment at or just before 02:00 affecting DB endpoint, ports, or credentials.\n",
      "- Observability anomaly: invalid timestamps indicate a logging library bug, time formatting error, or clock skew; verify NTP and log emitter.\n"
     ]
    }
   ],
   "source": [
    "with open(\"large_logs.txt\", \"r\") as f:\n",
    "    logs = f.read()\n",
    "\n",
    "summary_prompt = f\"\"\"\n",
    "You are an expert incident responder.\n",
    "Read the following logs and provide:\n",
    "1. A 3-sentence summary in plain English.\n",
    "2. The final incident severity (P1, P2, P3).\n",
    "3. Root cause hints in bullet points.\n",
    "\n",
    "Logs:\n",
    "{logs}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",  # large context model\n",
    "    messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRrqv-fk1I1Q",
    "outputId": "f3c6ee65-3396-45d3-8024-f8452054075a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total RAM is ~14 GB and it’s essentially all in use the whole time, split between “used” (app memory) and “cached/buffer” (reclaimable file cache). That’s normal on Linux—free RAM gets filled with cache.\n",
      "\n",
      "- Around 05:42 there’s a step-up of “used” memory by ~600–800 MB (likely a service start or workload ramp). The kernel trims a bit of cache and also evicts a small amount of cold pages to swap.\n",
      "\n",
      "- Swap rises only to ~19 MB and then stays flat—this is tiny and not a sign of real memory pressure.\n",
      "\n",
      "- Just before 06:00 the red swap line drops abruptly to 0. That usually means one of:\n",
      "  - the swapped-out pages were touched and paged back in, or\n",
      "  - swap was toggled (swapoff/swapon) or the workload ended, freeing those pages.\n",
      "  The change is too small to noticeably move the stacked bars.\n",
      "\n",
      "Bottom line: brief increase in working set caused a small amount of swapping; the system remained stable and not memory-starved. If you want to confirm what happened at ~06:00, check for a cron/systemd action or swap events (journalctl, swapon --show). If you prefer to avoid even small swaps, consider lowering vm.swappiness.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "image_path = \"/content/memory_graph.png\"\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",  # multimodal model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a monitoring assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Analyze this graph and explain what's happening.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base66,{base64_image}\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
